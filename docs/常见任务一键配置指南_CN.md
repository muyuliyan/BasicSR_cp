# BasicSR å¸¸è§ä»»åŠ¡ä¸€é”®é…ç½®æŒ‡å—

æœ¬æŒ‡å—æä¾›æœ€å¸¸è§çš„ä¸‰ç§ä»»åŠ¡ï¼ˆè¶…åˆ†è¾¨ç‡ã€å»å™ªã€ä¿®å¤ï¼‰çš„ä¸€é”®é…ç½®æ–¹æ³•ï¼Œè®©åˆå­¦è€…èƒ½å¿«é€Ÿä¸Šæ‰‹ã€‚

## ğŸ“š æ–‡æ¡£å¯¼èˆª

- **å®Œæ•´ä½¿ç”¨æŒ‡å—**: [BasicSR_ä½¿ç”¨æŒ‡å—_CN.md](BasicSR_ä½¿ç”¨æŒ‡å—_CN.md)
- **é…ç½®æ¨¡æ¿å‚è€ƒ**: [ä»»åŠ¡é…ç½®å¿«é€Ÿå‚è€ƒ_CN.md](ä»»åŠ¡é…ç½®å¿«é€Ÿå‚è€ƒ_CN.md)
- **æ•°æ®å‡†å¤‡**: [DatasetPreparation_CN.md](DatasetPreparation_CN.md)
- **è®­ç»ƒæµ‹è¯•**: [TrainTest_CN.md](TrainTest_CN.md)

---

## ğŸ” ä»»åŠ¡ä¸€ï¼šè¶…åˆ†è¾¨ç‡ (Image Super-Resolution)

### æ­¥éª¤ 1: å‡†å¤‡æ•°æ®

```bash
# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p datasets/MyDataset/{train,val}/{HR,LR}

# æ•°æ®ç»“æ„ç¤ºä¾‹
datasets/MyDataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ HR/          # é«˜åˆ†è¾¨ç‡è®­ç»ƒå›¾åƒ
â”‚   â””â”€â”€ LR/          # ä½åˆ†è¾¨ç‡è®­ç»ƒå›¾åƒ (å¯ç”¨è„šæœ¬ç”Ÿæˆ)
â””â”€â”€ val/
    â”œâ”€â”€ HR/          # é«˜åˆ†è¾¨ç‡éªŒè¯å›¾åƒ
    â””â”€â”€ LR/          # ä½åˆ†è¾¨ç‡éªŒè¯å›¾åƒ
```

### æ­¥éª¤ 2: ç”Ÿæˆä½åˆ†è¾¨ç‡å›¾åƒ (å¦‚éœ€è¦)

```python
# ç”Ÿæˆ4å€ä¸‹é‡‡æ ·çš„LRå›¾åƒ
import cv2
import os
from glob import glob

def generate_lr_images(hr_path, lr_path, scale=4):
    os.makedirs(lr_path, exist_ok=True)
    hr_images = glob(os.path.join(hr_path, '*.png'))
    
    for img_path in hr_images:
        img = cv2.imread(img_path)
        h, w = img.shape[:2]
        lr_img = cv2.resize(img, (w//scale, h//scale), interpolation=cv2.INTER_CUBIC)
        
        filename = os.path.basename(img_path)
        save_path = os.path.join(lr_path, filename)
        cv2.imwrite(save_path, lr_img)
        print(f"Generated: {save_path}")

# ä½¿ç”¨ç¤ºä¾‹
generate_lr_images('datasets/MyDataset/train/HR', 'datasets/MyDataset/train/LR', scale=4)
generate_lr_images('datasets/MyDataset/val/HR', 'datasets/MyDataset/val/LR', scale=4)
```

### æ­¥éª¤ 3: é…ç½®æ–‡ä»¶ (ä¿å­˜ä¸º `options/train/my_sr_config.yml`)

```yaml
# åŸºæœ¬è®¾ç½®
name: my_sr_x4_experiment
model_type: SRModel
scale: 4
num_gpu: 1
manual_seed: 0

# æ•°æ®é›†è®¾ç½®
datasets:
  train:
    name: MyDataset
    type: PairedImageDataset
    dataroot_gt: datasets/MyDataset/train/HR
    dataroot_lq: datasets/MyDataset/train/LR
    filename_tmpl: '{}'
    io_backend:
      type: disk
    
    gt_size: 128
    use_hflip: true
    use_rot: true
    num_worker_per_gpu: 4
    batch_size_per_gpu: 16
    dataset_enlarge_ratio: 100
    
  val:
    name: MyValidation
    type: PairedImageDataset
    dataroot_gt: datasets/MyDataset/val/HR
    dataroot_lq: datasets/MyDataset/val/LR
    io_backend:
      type: disk

# ç½‘ç»œç»“æ„ (æ¨èåˆå­¦è€…ä½¿ç”¨)
network_g:
  type: MSRResNet
  num_in_ch: 3
  num_out_ch: 3
  num_feat: 64
  num_block: 16
  upscale: 4

# è·¯å¾„è®¾ç½®
path:
  pretrain_network_g: ~
  strict_load_g: true
  resume_state: ~

# è®­ç»ƒè®¾ç½®
train:
  ema_decay: 0.999
  optim_g:
    type: Adam
    lr: !!float 2e-4
    weight_decay: 0
    betas: [0.9, 0.99]
  
  scheduler:
    type: CosineAnnealingRestartLR
    periods: [100000, 100000, 100000, 100000]
    restart_weights: [1, 1, 1, 1]
    eta_min: !!float 1e-7
  
  total_iter: 400000
  warmup_iter: -1
  
  pixel_opt:
    type: L1Loss
    loss_weight: 1.0
    reduction: mean

# éªŒè¯è®¾ç½®
val:
  val_freq: !!float 5e3
  save_img: true
  
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 4
      test_y_channel: false

# æ—¥å¿—è®¾ç½®
logger:
  print_freq: 100
  save_checkpoint_freq: !!float 5e3
  use_tb_logger: true
  wandb:
    project: ~
    resume_id: ~

# åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®
dist_params:
  backend: nccl
  port: 29500
```

### æ­¥éª¤ 4: å¼€å§‹è®­ç»ƒ

```bash
# å•GPUè®­ç»ƒ
python basicsr/train.py -opt options/train/my_sr_config.yml

# å¤šGPUè®­ç»ƒ (å¦‚æœ‰4å¼ å¡)
python -m torch.distributed.launch --nproc_per_node=4 --master_port=4321 basicsr/train.py -opt options/train/my_sr_config.yml --launcher pytorch
```

---

## ğŸ”‡ ä»»åŠ¡äºŒï¼šå›¾åƒå»å™ª (Image Denoising)

### æ­¥éª¤ 1: å‡†å¤‡å»å™ªæ•°æ®

```bash
# åˆ›å»ºå»å™ªæ•°æ®ç›®å½•
mkdir -p datasets/Denoise/{train,val}/{GT,Noisy}
```

### æ­¥éª¤ 2: ç”Ÿæˆå«å™ªå›¾åƒ

```python
# æ·»åŠ é«˜æ–¯å™ªå£°
import cv2
import numpy as np
import os
from glob import glob

def add_gaussian_noise(clean_path, noisy_path, noise_level=25):
    """ç»™å›¾åƒæ·»åŠ é«˜æ–¯å™ªå£°"""
    os.makedirs(noisy_path, exist_ok=True)
    clean_images = glob(os.path.join(clean_path, '*.png'))
    
    for img_path in clean_images:
        # è¯»å–å›¾åƒå¹¶å½’ä¸€åŒ–åˆ°[0,1]
        img = cv2.imread(img_path).astype(np.float32) / 255.0
        
        # æ·»åŠ é«˜æ–¯å™ªå£°
        noise = np.random.normal(0, noise_level/255.0, img.shape)
        noisy_img = img + noise
        noisy_img = np.clip(noisy_img, 0, 1)
        
        # ä¿å­˜å«å™ªå›¾åƒ
        filename = os.path.basename(img_path)
        save_path = os.path.join(noisy_path, filename)
        cv2.imwrite(save_path, (noisy_img * 255).astype(np.uint8))
        print(f"Generated noisy image: {save_path}")

# ç”Ÿæˆè®­ç»ƒå’ŒéªŒè¯çš„å«å™ªå›¾åƒ
add_gaussian_noise('datasets/Denoise/train/GT', 'datasets/Denoise/train/Noisy', noise_level=25)
add_gaussian_noise('datasets/Denoise/val/GT', 'datasets/Denoise/val/Noisy', noise_level=25)
```

### æ­¥éª¤ 3: å»å™ªé…ç½®æ–‡ä»¶ (ä¿å­˜ä¸º `options/train/my_denoise_config.yml`)

```yaml
# åŸºæœ¬è®¾ç½®
name: my_denoise_sigma25_experiment
model_type: SRModel
scale: 1  # å»å™ªä¸æ”¹å˜åˆ†è¾¨ç‡
num_gpu: 1
manual_seed: 0

# æ•°æ®é›†è®¾ç½®
datasets:
  train:
    name: DenoiseDataset
    type: PairedImageDataset
    dataroot_gt: datasets/Denoise/train/GT
    dataroot_lq: datasets/Denoise/train/Noisy
    filename_tmpl: '{}'
    io_backend:
      type: disk
    
    gt_size: 128
    use_hflip: true
    use_rot: true
    num_worker_per_gpu: 4
    batch_size_per_gpu: 16
    dataset_enlarge_ratio: 100
    
  val:
    name: DenoiseValidation
    type: PairedImageDataset
    dataroot_gt: datasets/Denoise/val/GT
    dataroot_lq: datasets/Denoise/val/Noisy
    io_backend:
      type: disk

# ç½‘ç»œç»“æ„ (ä½¿ç”¨RIDNetè¿›è¡Œå»å™ª)
network_g:
  type: RIDNet
  num_in_ch: 3
  num_feat: 64
  num_out_ch: 3

# è®­ç»ƒè®¾ç½®
train:
  ema_decay: 0.999
  optim_g:
    type: Adam
    lr: !!float 1e-4  # å»å™ªä½¿ç”¨è¾ƒå°å­¦ä¹ ç‡
    weight_decay: 0
    betas: [0.9, 0.999]
  
  scheduler:
    type: MultiStepLR
    milestones: [50000, 100000, 150000, 200000]
    gamma: 0.5
  
  total_iter: 300000
  warmup_iter: -1
  
  pixel_opt:
    type: L1Loss
    loss_weight: 1.0
    reduction: mean

# éªŒè¯è®¾ç½®
val:
  val_freq: !!float 5e3
  save_img: true
  
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 0  # å»å™ªé€šå¸¸ä¸è£å‰ªè¾¹ç•Œ
      test_y_channel: false

# æ—¥å¿—è®¾ç½®
logger:
  print_freq: 100
  save_checkpoint_freq: !!float 5e3
  use_tb_logger: true

dist_params:
  backend: nccl
  port: 29500
```

### æ­¥éª¤ 4: å¼€å§‹å»å™ªè®­ç»ƒ

```bash
python basicsr/train.py -opt options/train/my_denoise_config.yml
```

---

## ğŸ–¼ï¸ ä»»åŠ¡ä¸‰ï¼šJPEGå‹ç¼©ä¼ªå½±å»é™¤

### æ­¥éª¤ 1: å‡†å¤‡JPEGå‹ç¼©æ•°æ®

```bash
mkdir -p datasets/JPEG_CAR/{train,val}/{GT,Compressed}
```

### æ­¥éª¤ 2: ç”ŸæˆJPEGå‹ç¼©å›¾åƒ

```python
# ç”ŸæˆJPEGå‹ç¼©ä¼ªå½±æ•°æ®
import cv2
from PIL import Image
import os
from glob import glob

def compress_jpeg(clean_path, compressed_path, quality=10):
    """ç”ŸæˆJPEGå‹ç¼©å›¾åƒ"""
    os.makedirs(compressed_path, exist_ok=True)
    clean_images = glob(os.path.join(clean_path, '*.png'))
    
    for img_path in clean_images:
        # ä½¿ç”¨PILè¿›è¡ŒJPEGå‹ç¼©
        img = Image.open(img_path)
        filename = os.path.splitext(os.path.basename(img_path))[0]
        
        # ä¿å­˜ä¸ºJPEGæ ¼å¼ï¼ˆæœ‰æŸå‹ç¼©ï¼‰
        jpeg_path = os.path.join(compressed_path, f"{filename}.jpg")
        img.save(jpeg_path, 'JPEG', quality=quality)
        
        # å†è¯»å–å¹¶ä¿å­˜ä¸ºPNGç”¨äºè®­ç»ƒ
        compressed_img = Image.open(jpeg_path)
        png_path = os.path.join(compressed_path, f"{filename}.png")
        compressed_img.save(png_path, 'PNG')
        
        # åˆ é™¤ä¸­é—´JPEGæ–‡ä»¶
        os.remove(jpeg_path)
        print(f"Generated compressed image: {png_path}")

# ç”Ÿæˆè´¨é‡å› å­ä¸º10çš„JPEGå‹ç¼©å›¾åƒ
compress_jpeg('datasets/JPEG_CAR/train/GT', 'datasets/JPEG_CAR/train/Compressed', quality=10)
compress_jpeg('datasets/JPEG_CAR/val/GT', 'datasets/JPEG_CAR/val/Compressed', quality=10)
```

### æ­¥éª¤ 3: JPEGä¿®å¤é…ç½®æ–‡ä»¶ (ä¿å­˜ä¸º `options/train/my_jpeg_car_config.yml`)

```yaml
# åŸºæœ¬è®¾ç½®
name: my_jpeg_car_q10_experiment
model_type: SwinIRModel
scale: 1
num_gpu: 1
manual_seed: 0

# æ•°æ®é›†è®¾ç½®
datasets:
  train:
    name: JPEG_CAR_Dataset
    type: PairedImageDataset
    dataroot_gt: datasets/JPEG_CAR/train/GT
    dataroot_lq: datasets/JPEG_CAR/train/Compressed
    filename_tmpl: '{}'
    io_backend:
      type: disk
    
    gt_size: 96
    use_hflip: true
    use_rot: true
    num_worker_per_gpu: 4
    batch_size_per_gpu: 16
    dataset_enlarge_ratio: 100
    
  val:
    name: JPEG_CAR_Validation
    type: PairedImageDataset
    dataroot_gt: datasets/JPEG_CAR/val/GT
    dataroot_lq: datasets/JPEG_CAR/val/Compressed
    io_backend:
      type: disk

# ç½‘ç»œç»“æ„ (SwinIRä¸“ç”¨äºJPEGå‹ç¼©ä¼ªå½±å»é™¤)
network_g:
  type: SwinIR
  upscale: 1
  in_chans: 3
  img_size: 64
  window_size: 7  # JPEGä»»åŠ¡ä½¿ç”¨7
  img_range: 1.
  depths: [6, 6, 6, 6, 6, 6]
  embed_dim: 180
  num_heads: [6, 6, 6, 6, 6, 6]
  mlp_ratio: 2
  upsampler: ''
  resi_connection: '1conv'

# è®­ç»ƒè®¾ç½®
train:
  ema_decay: 0.999
  optim_g:
    type: Adam
    lr: !!float 2e-4
    weight_decay: 0
    betas: [0.9, 0.99]
  
  scheduler:
    type: CosineAnnealingRestartLR
    periods: [92000]
    restart_weights: [1]
    eta_min: !!float 1e-7
  
  total_iter: 92000
  warmup_iter: -1
  
  pixel_opt:
    type: L1Loss
    loss_weight: 1.0
    reduction: mean

# éªŒè¯è®¾ç½®
val:
  val_freq: !!float 2e3
  save_img: true
  
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 0
      test_y_channel: false

# æ—¥å¿—è®¾ç½®
logger:
  print_freq: 100
  save_checkpoint_freq: !!float 2e3
  use_tb_logger: true

dist_params:
  backend: nccl
  port: 29500
```

### æ­¥éª¤ 4: å¼€å§‹JPEGä¿®å¤è®­ç»ƒ

```bash
python basicsr/train.py -opt options/train/my_jpeg_car_config.yml
```

---

## ğŸ“Š æµ‹è¯•å’Œè¯„ä¼°

### åˆ›å»ºæµ‹è¯•é…ç½®æ–‡ä»¶

ä»¥è¶…åˆ†è¾¨ç‡ä¸ºä¾‹ï¼Œä¿å­˜ä¸º `options/test/my_sr_test.yml`:

```yaml
name: test_my_sr_x4
model_type: SRModel
scale: 4
num_gpu: 1

datasets:
  test_1:
    name: MyTestSet
    type: PairedImageDataset
    dataroot_gt: datasets/MyDataset/val/HR
    dataroot_lq: datasets/MyDataset/val/LR
    io_backend:
      type: disk

network_g:
  type: MSRResNet
  num_in_ch: 3
  num_out_ch: 3
  num_feat: 64
  num_block: 16
  upscale: 4

path:
  pretrain_network_g: experiments/my_sr_x4_experiment/models/net_g_latest.pth
  strict_load_g: true

val:
  save_img: true
  suffix: ~
  
  metrics:
    psnr:
      type: calculate_psnr
      crop_border: 4
      test_y_channel: false
    ssim:
      type: calculate_ssim
      crop_border: 4
      test_y_channel: false
```

### è¿è¡Œæµ‹è¯•

```bash
# æµ‹è¯•æ¨¡å‹
python basicsr/test.py -opt options/test/my_sr_test.yml

# è®¡ç®—æ›´å¤šæŒ‡æ ‡
python scripts/metrics/calculate_psnr_ssim.py --gt datasets/MyDataset/val/HR --restored results/test_my_sr_x4/MyTestSet --crop_border 4
```

---

## ğŸ› ï¸ å®ç”¨å·¥å…·è„šæœ¬

### 1. æ‰¹é‡å›¾åƒè½¬æ¢

```python
# convert_images.py - æ‰¹é‡è½¬æ¢å›¾åƒæ ¼å¼
import cv2
import os
from glob import glob

def convert_images(input_dir, output_dir, target_format='png'):
    """æ‰¹é‡è½¬æ¢å›¾åƒæ ¼å¼"""
    os.makedirs(output_dir, exist_ok=True)
    
    # æ”¯æŒçš„è¾“å…¥æ ¼å¼
    patterns = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
    
    for pattern in patterns:
        files = glob(os.path.join(input_dir, pattern))
        files.extend(glob(os.path.join(input_dir, pattern.upper())))
        
        for file_path in files:
            img = cv2.imread(file_path)
            if img is not None:
                base_name = os.path.splitext(os.path.basename(file_path))[0]
                output_path = os.path.join(output_dir, f"{base_name}.{target_format}")
                cv2.imwrite(output_path, img)
                print(f"Converted: {file_path} -> {output_path}")

# ä½¿ç”¨ç¤ºä¾‹
# convert_images('input_folder', 'output_folder', 'png')
```

### 2. å›¾åƒè´¨é‡æ£€æŸ¥

```python
# check_image_quality.py - æ£€æŸ¥å›¾åƒè´¨é‡
import cv2
import numpy as np
from glob import glob

def check_images(folder_path):
    """æ£€æŸ¥å›¾åƒåŸºæœ¬ä¿¡æ¯"""
    images = glob(os.path.join(folder_path, '*.png'))
    
    resolutions = {}
    corrupted = []
    
    for img_path in images:
        try:
            img = cv2.imread(img_path)
            if img is None:
                corrupted.append(img_path)
                continue
                
            h, w = img.shape[:2]
            resolution = f"{w}x{h}"
            resolutions[resolution] = resolutions.get(resolution, 0) + 1
            
        except Exception as e:
            corrupted.append(img_path)
            print(f"Error reading {img_path}: {e}")
    
    print(f"Total images: {len(images)}")
    print(f"Corrupted images: {len(corrupted)}")
    print("Resolutions found:")
    for res, count in resolutions.items():
        print(f"  {res}: {count} images")
    
    return corrupted

# ä½¿ç”¨ç¤ºä¾‹
# corrupted = check_images('datasets/MyDataset/train/HR')
```

### 3. è®­ç»ƒç›‘æ§è„šæœ¬

```python
# monitor_training.py - ç›‘æ§è®­ç»ƒè¿›åº¦
import os
import time
from glob import glob

def monitor_training(experiment_dir):
    """ç›‘æ§è®­ç»ƒè¿›åº¦"""
    log_file = os.path.join(experiment_dir, 'train.log')
    
    if not os.path.exists(log_file):
        print(f"Log file not found: {log_file}")
        return
    
    print(f"Monitoring: {log_file}")
    print("Press Ctrl+C to stop monitoring")
    
    try:
        with open(log_file, 'r') as f:
            # ç§»åŠ¨åˆ°æ–‡ä»¶æœ«å°¾
            f.seek(0, 2)
            
            while True:
                line = f.readline()
                if line:
                    # è¿‡æ»¤åŒ…å«å…³é”®ä¿¡æ¯çš„è¡Œ
                    if any(keyword in line for keyword in ['iter:', 'psnr:', 'loss:', 'lr:']):
                        print(line.strip())
                else:
                    time.sleep(1)
                    
    except KeyboardInterrupt:
        print("\nMonitoring stopped.")

# ä½¿ç”¨ç¤ºä¾‹
# monitor_training('experiments/my_sr_x4_experiment')
```

---

## â“ å¸¸è§é—®é¢˜è§£å†³

### Q1: è®­ç»ƒè¿‡ç¨‹ä¸­æ˜¾å­˜ä¸è¶³
```bash
# è§£å†³æ–¹æ¡ˆï¼šå‡å°‘batch sizeå’Œpatch size
datasets:
  train:
    gt_size: 64        # ä»128å‡å°‘åˆ°64
    batch_size_per_gpu: 8  # ä»16å‡å°‘åˆ°8
```

### Q2: è®­ç»ƒé€Ÿåº¦å¤ªæ…¢
```bash
# è§£å†³æ–¹æ¡ˆï¼šè°ƒæ•´æ•°æ®åŠ è½½å‚æ•°
datasets:
  train:
    num_worker_per_gpu: 8      # å¢åŠ æ•°æ®åŠ è½½è¿›ç¨‹
    prefetch_mode: cuda        # ä½¿ç”¨CUDAé¢„å–
    dataset_enlarge_ratio: 1   # å‡å°‘æ•°æ®é‡å¤æ¬¡æ•°
```

### Q3: éªŒè¯PSNRä¸æå‡
```yaml
# æ£€æŸ¥è·¯å¾„æ˜¯å¦æ­£ç¡®
datasets:
  val:
    dataroot_gt: datasets/correct/path/to/GT  # ç¡®ä¿è·¯å¾„æ­£ç¡®
    dataroot_lq: datasets/correct/path/to/LR
```

### Q4: æ¨¡å‹åŠ è½½å¤±è´¥
```yaml
# è®¾ç½®æ›´å®½æ¾çš„åŠ è½½æ¨¡å¼
path:
  strict_load_g: false  # å…è®¸éƒ¨åˆ†å‚æ•°ä¸åŒ¹é…
```

---

## ğŸ“ˆ è¿›é˜¶æŠ€å·§

1. **ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹åŠ é€Ÿè®­ç»ƒ**:
   ```yaml
   path:
     pretrain_network_g: experiments/pretrained_models/MSRResNet.pth
   ```

2. **å¯ç”¨EMA(æŒ‡æ•°ç§»åŠ¨å¹³å‡)**:
   ```yaml
   train:
     ema_decay: 0.999  # é€šå¸¸èƒ½æå‡æ¨¡å‹ç¨³å®šæ€§
   ```

3. **æ··åˆç²¾åº¦è®­ç»ƒèŠ‚çœæ˜¾å­˜**:
   ```yaml
   train:
     use_amp: true  # å¯ç”¨è‡ªåŠ¨æ··åˆç²¾åº¦
   ```

4. **ä½¿ç”¨Wandbç›‘æ§è®­ç»ƒ**:
   ```yaml
   logger:
     wandb:
       project: my_project_name
       entity: your_username
   ```

è¿™ä»½æŒ‡å—æ¶µç›–äº†æœ€å¸¸è§çš„ä½¿ç”¨åœºæ™¯ï¼Œå¦‚éœ€æ›´è¯¦ç»†çš„è¯´æ˜ï¼Œè¯·å‚è€ƒå®Œæ•´çš„ä½¿ç”¨æŒ‡å—ã€‚